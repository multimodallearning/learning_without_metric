{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jEutADJuHgfb",
    "outputId": "76403e33-7b57-4da4-896e-31a12fd04d67"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.checkpoint import checkpoint as checkpoint\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "#ct_data = torch.load('data2d_ct.pth')\n",
    "#data_mr = torch.load('data2d_mr.pth')\n",
    "\n",
    "#ct_imgs_train = torch.clamp(torch.from_numpy(ct_data['imgs']).float()[:,:,32:192+64,16:16+256]+300,0,600).contiguous().cuda()/600\n",
    "#ct_segs_train = torch.from_numpy(ct_data['segs']).long()[:,32:192+64,16:16+256].contiguous().cuda()\n",
    "\n",
    "#mr_imgs = torch.clamp(torch.from_numpy(data_mr['imgs'][:8,:,32:192+64,16:16+256]).float(),0,400).contiguous().cuda()/400\n",
    "#mr_segs = torch.from_numpy(data_mr['segs']).long()[:8,32:192+64,16:16+256].contiguous().cuda()\n",
    "\n",
    "ct_imgs = torch.zeros(9,1,224,256).cuda()\n",
    "ct_segs = torch.zeros(9,224,256).cuda()\n",
    "\n",
    "mr_imgs = torch.zeros(9,1,224,256).cuda()\n",
    "mr_segs = torch.zeros(9,224,256).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FOLD == 0:\n",
    "    ids_train = [0,1,2,3,4,5]\n",
    "    ids_test = [6,7,8]\n",
    "    \n",
    "if FOLD == 1:\n",
    "    ids_train = [0,1,2,6,7,8]\n",
    "    ids_test = [3,4,5]\n",
    "    \n",
    "if FOLD == 2:\n",
    "    ids_train = [3,4,5,6,7,8]\n",
    "    ids_test = [0,1,2]\n",
    "\n",
    "ct_imgs_train = ct_imgs[ids_train]\n",
    "ct_segs_train = ct_segs[ids_train]\n",
    "mr_imgs_train = mr_imgs[ids_train]\n",
    "mr_segs_train = mr_segs[ids_train]\n",
    "\n",
    "ct_imgs_test = ct_imgs[ids_test]\n",
    "ct_segs_test = ct_segs[ids_test]\n",
    "mr_imgs_test = mr_imgs[ids_test]\n",
    "mr_segs_test = mr_segs[ids_test]\n",
    "\n",
    "\n",
    "print(ct_imgs_train.shape, ct_imgs_test.shape)\n",
    "print(ct_segs_train.shape, ct_segs_test.shape)\n",
    "\n",
    "print(mr_imgs_train.shape, mr_imgs_test.shape)\n",
    "print(mr_segs_train.shape, mr_segs_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShLovVGb09Ho",
    "outputId": "6c2615c7-cb25-4b6a-9027-1026a7b30244"
   },
   "outputs": [],
   "source": [
    "def parameter_count(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def dice_coeff(outputs, labels, max_label):\n",
    "    dice = torch.FloatTensor(max_label-1).fill_(0)\n",
    "    for label_num in range(1, max_label):\n",
    "        iflat = (outputs==label_num).view(-1).float()\n",
    "        tflat = (labels==label_num).view(-1).float()\n",
    "        intersection = torch.mean(iflat * tflat)\n",
    "        dice[label_num-1] = (2. * intersection) / (1e-8 + torch.mean(iflat) + torch.mean(tflat))\n",
    "    return dice\n",
    "\n",
    "\n",
    "def jacobian_det(est_x2):\n",
    "    B,C,H,W = est_x2.size()\n",
    "    est_pix = torch.zeros_like(est_x2)\n",
    "    est_pix[:,0,:,:] = est_x2[:,0,:,:]*(H-1)/2.0\n",
    "    est_pix[:,1,:,:] = est_x2[:,1,:,:]*(W-1)/2.0\n",
    "    gradx = nn.Conv2d(2,2,(3,1),padding=(1,0),bias=False,groups=2)\n",
    "    gradx.weight.data[:,0,:,0] = torch.tensor([-0.5,0,0.5]).view(1,3).repeat(2,1)\n",
    "    gradx.to(est_x2.device)\n",
    "    grady = nn.Conv2d(2,2,(1,3),padding=(0,1),bias=False,groups=2)\n",
    "    grady.weight.data[:,0,0,:] = torch.tensor([-0.5,0,0.5]).view(1,3).repeat(2,1)\n",
    "    grady.to(est_x2.device)\n",
    "    with torch.no_grad():\n",
    "        J1 = gradx(est_pix)\n",
    "        J2 = grady(est_pix)\n",
    "    J = (J1[:,0,:,:]+1)*(J2[:,1,:,:]+1)-(J1[:,1,:,:])*(J2[:,0,:,:])\n",
    "    return J\n",
    "\n",
    "\n",
    "def Correlation(pad_size,kernel_size,max_displacement,stride1,stride2,corr_multiply):\n",
    "    disp_hw = max_displacement\n",
    "    corr_unfold = torch.nn.Unfold((disp_hw+1,disp_hw+1),dilation=(stride2,stride2),padding=disp_hw//2)\n",
    "\n",
    "    def applyCorr(feat1,feat2):\n",
    "        B,C,H,W = feat1.size()\n",
    "        return torch.mean(corr_unfold(feat2).view(B,C,-1,H,W)*(feat1).unsqueeze(2),1)\n",
    "\n",
    "    return applyCorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6QrZ7gupS4J",
    "outputId": "150d1466-d85f-4f15-b4ab-60b74e71625d"
   },
   "outputs": [],
   "source": [
    "class MultimodalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultimodalNet, self).__init__()\n",
    "        self.identity = F.affine_grid(torch.eye(2,3).cuda().unsqueeze(0),(1,1,224,256),align_corners=False)\n",
    "\n",
    "        self.Y1 = nn.Sequential(nn.Conv2d(1,32,5,stride=2,padding=2),nn.InstanceNorm2d(32),nn.ReLU(),\\\n",
    "                                nn.Conv2d(32,32,3,stride=2,padding=1),nn.InstanceNorm2d(32),nn.ReLU(),\\\n",
    "                                nn.Conv2d(32,48,3,stride=1,padding=1),nn.InstanceNorm2d(48),nn.ReLU())\n",
    "        self.Y2 = nn.Sequential(nn.Conv2d(1,32,5,stride=2,padding=2),nn.InstanceNorm2d(32),nn.ReLU(),\\\n",
    "                                nn.Conv2d(32,32,3,stride=2,padding=1),nn.InstanceNorm2d(32),nn.ReLU(),\\\n",
    "                                nn.Conv2d(32,48,3,stride=1,padding=1),nn.InstanceNorm2d(48),nn.ReLU())\n",
    "        \n",
    "        self.corr = Correlation(pad_size=14,kernel_size=1,max_displacement=14,stride1=1,stride2=1,corr_multiply=1)\n",
    "        \n",
    "        self.reg = nn.Sequential(nn.Conv2d(225+32,128,3,stride=2,padding=1),nn.BatchNorm2d(128),nn.ReLU(),\\\n",
    "                                 nn.Conv2d(128,64,3,padding=1),nn.BatchNorm2d(64),nn.ReLU(),\\\n",
    "                                 nn.Conv2d(64,64,3,padding=1),nn.BatchNorm2d(64),nn.ReLU(),nn.Conv2d(64,2,1),\\\n",
    "                                 nn.AvgPool2d(3,stride=1,padding=1),nn.AvgPool2d(3,stride=1,padding=1),\\\n",
    "                                 nn.Upsample(scale_factor=4,mode='bicubic',align_corners=False),\\\n",
    "                                 nn.AvgPool2d(3,stride=1,padding=1),nn.AvgPool2d(3,stride=1,padding=1),\n",
    "                                 nn.Upsample(scale_factor=2,mode='bicubic',align_corners=False))\n",
    "\n",
    "    def forward(self, x1,x2, swap):\n",
    "        if(swap):\n",
    "            y1 = self.Y2(x1)\n",
    "            y2 = self.Y1(x2)\n",
    "        else:\n",
    "            y1 = self.Y1(x1)\n",
    "            y2 = self.Y2(x2)\n",
    "        corr_tensor = torch.cat((checkpoint(self.corr,y1[:,:32],y2[:,:32]),y1[:,32:],y2[:,32:]),1)\n",
    "        field = checkpoint(self.reg,corr_tensor)\n",
    "        return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6QrZ7gupS4J",
    "outputId": "150d1466-d85f-4f15-b4ab-60b74e71625d"
   },
   "outputs": [],
   "source": [
    "net = MultimodalNet()\n",
    "net.cuda()\n",
    "print('#parameters: ', parameter_count(net))\n",
    "\n",
    "smooth = nn.Sequential(nn.AvgPool2d(7,stride=1,padding=3),nn.AvgPool2d(7,stride=1,padding=3),nn.AvgPool2d(5,stride=1,padding=2),nn.Upsample(scale_factor=4,mode='bicubic',align_corners=False),\\\n",
    "                       nn.AvgPool2d(9,stride=1,padding=4),nn.AvgPool2d(9,stride=1,padding=4),nn.Upsample(scale_factor=2,mode='bicubic',align_corners=False))\n",
    "\n",
    "\n",
    "H,W = ct_imgs_train.shape[-2:]\n",
    "B = 4\n",
    "n_iter = 7500\n",
    "alpha_ = torch.linspace(.9,.6,n_iter)\n",
    "beta_ = 1\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "\n",
    "identity = F.affine_grid(torch.eye(2,3).cuda().unsqueeze(0),(1,1,H,W),align_corners=False)\n",
    "run_dice = torch.zeros(n_iter)\n",
    "run_dice0 = torch.zeros(n_iter)\n",
    "run_jacdet = torch.zeros(n_iter)\n",
    "cycle_loss = torch.zeros(n_iter)\n",
    "t0 = time.time()\n",
    "\n",
    "\n",
    "for i in range(n_iter):\n",
    "    optimizer.zero_grad()\n",
    "    idx1 = torch.randperm(len(ids_train))[:B]\n",
    "    idx2 = torch.randperm(len(ids_train))[:B]\n",
    "    t1 = ct_imgs_train[idx1]\n",
    "    t2 = mr_imgs_train[idx2]\n",
    "    seg_t1 = ct_segs_train[idx1]\n",
    "    seg_t2 = mr_segs_train[idx2]\n",
    "    \n",
    "\n",
    "    # residual prediction\n",
    "    with torch.no_grad():\n",
    "        field12_ = net(t1,t2,False).detach()\n",
    "        field21_ = net(t2,t1,True).detach()\n",
    "        \n",
    "    #synthetic field\n",
    "    synth13 = beta_*field12_+smooth(alpha_[i]*torch.randn(B,2,H//8,W//8).cuda())\n",
    "    t3 = F.grid_sample(t1,synth13.permute(0,2,3,1)+identity,align_corners=False,padding_mode='border')\n",
    "    synth24 = beta_*field21_+smooth(alpha_[i]*torch.randn(B,2,H//8,W//8).cuda())\n",
    "    t4 = F.grid_sample(t2,synth24.permute(0,2,3,1)+identity,align_corners=False,padding_mode='border')\n",
    "\n",
    "    #two cycles 12 + 23 = 13 and 21 + 14 = 24 (four estimated multimodal registrations, two known monomodal ones)\n",
    "    field12 = net(t1,t2,False)\n",
    "    field23 = net(t2,t3,True)\n",
    "    field21 = net(t2,t1,True)\n",
    "    field14 = net(t1,t4,False)\n",
    "    combi1223 = F.grid_sample(field12,field23.permute(0,2,3,1)+identity,align_corners=False)+field23\n",
    "    combi2114 = F.grid_sample(field21,field14.permute(0,2,3,1)+identity,align_corners=False)+field14\n",
    "    cycle1_loss = nn.MSELoss()(synth13,combi1223)\n",
    "    cycle2_loss = nn.MSELoss()(synth24,combi2114)\n",
    "    loss = cycle1_loss + cycle2_loss\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        warped = F.grid_sample(seg_t2.float().unsqueeze(1),field21.permute(0,2,3,1)+identity,align_corners=False,mode='nearest',padding_mode='border').squeeze().long()\n",
    "        run_dice[i] = dice_coeff(seg_t1,warped,8)[torch.Tensor([0,1,3,4,5,6]).long()].mean().cpu()\n",
    "        run_dice0[i] = dice_coeff(seg_t1,seg_t2,8)[torch.Tensor([0,1,3,4,5,6]).long()].mean().cpu()\n",
    "        J = jacobian_det(field12)\n",
    "        run_jacdet[i] = J.std().cpu()\n",
    "    \n",
    "    cycle_loss[i] = loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step() \n",
    "    \n",
    "    if(i%100==19):\n",
    "        print(i,'dice',run_dice[i-18:i].mean().item(),'before',run_dice0[i-18:i].mean().item(),'jacdet',run_jacdet[i-18:i].mean().item(),'cycle_loss',cycle_loss[i-18:i].mean().item(),'t',time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = len(ids_test)\n",
    "\n",
    "d0_mean = torch.zeros(n_test**2)\n",
    "d1_mean = torch.zeros(n_test**2)\n",
    "d0 = torch.zeros(n_test**2,6)\n",
    "d1 = torch.zeros(n_test**2,6)\n",
    "\n",
    "print('test FOLD', FOLD)\n",
    "idx = 0\n",
    "for i in range(n_test):\n",
    "    for j in range(n_test):\n",
    "        t1 = ct_imgs_test[i:i+1].cuda()\n",
    "        t2 = mr_imgs_test[j:j+1]\n",
    "        seg_t1 = ct_segs_test[i:i+1]\n",
    "        seg_t2 = mr_segs_test[j:j+1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            field21 = net(t2,t1,True)\n",
    "        \n",
    "        warped = F.grid_sample(seg_t2.float().unsqueeze(1),field21.permute(0,2,3,1)+identity,align_corners=False,mode='nearest',padding_mode='border').squeeze().long()\n",
    "        d1[idx,:] = dice_coeff(seg_t1,warped,8)[torch.Tensor([0,1,3,4,5,6]).long()].cpu()\n",
    "        d0[idx,:] = dice_coeff(seg_t1,seg_t2,8)[torch.Tensor([0,1,3,4,5,6]).long()].cpu()\n",
    "        d1_mean[idx] = d1[idx,:].mean()\n",
    "        d0_mean[idx] = d0[idx,:].mean()\n",
    "        idx+=1\n",
    "        \n",
    "\n",
    "print('d0', d0_mean.mean())\n",
    "print('d1', d1_mean.mean())\n",
    "print('d0 mean', d0.mean(dim=0))\n",
    "print('d1 mean', d1.mean(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YR5Rd3A9xle_",
    "outputId": "2378dc93-eee1-44d1-a17d-fa7eecd4073c"
   },
   "outputs": [],
   "source": [
    "torch.save(net.cpu().state_dict(),'net2d_cycle_fold{}.pth'.format(FOLD))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "learn_multimodal_shift_synth_ice_clean.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
